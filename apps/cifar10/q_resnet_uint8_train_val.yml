# =========================== Basic Settings ===========================
# machine info
num_gpus_per_job: 1  # number of gpus each job need
num_cpus_per_job: 4  # number of cpus each job need
memory_per_job: 8  # memory requirement each job need
gpu_type: "nvidia-rtx-a6000"

# data
dataset: CIFAR10
data_transforms: cifar
data_loader: cifar
dataset_dir: /path/to/data
data_loader_workers: 5 #10

# info
num_classes: 10
image_size: 32
topk: [1, 5]
num_epochs: 1 #150

#FL setup
num_iters: 2000
num_clients: 4
num_workers: 4
knowledge_distillation: True
data_dir: data/cifar10
device: cpu

# optimizer
optimizer: sgd
momentum: 0.9
weight_decay: 0.00004
nesterov: True

# lr
lr: 0.1
lr_scheduler: multistep
multistep_lr_milestones: [100, 150]
multistep_lr_gamma: 0.1
lr_scheduler: linear_decaying
#lr_scheduler: butterworth_iter #mixed_iter #gaussian_iter #exp_decaying_iter #cos_annealing_iter
#exp_decaying_gamma: 0.98

# model profiling
profiling: [gpu]
#model_profiling_verbose: True

# pretrain, resume, test_only
pretrained_dir: ''
pretrained_file: ''
resume: ''
test_only: False

#
random_seed: 1995
batch_size: 512 #1024 #256 #512 #256 #1024 #4096 #1024 #256
model: ''
reset_parameters: True

#
distributed: False #True
distributed_all_reduce: True #True
use_diff_seed: False #True

#
stats_sharing: False

#
#unbiased: False
clamp: True
rescale: True #False
rescale_conv: True #False
switchbn: True #False
#normalize: False
bn_calib: False
rescale_type: constant #[stddev, constant]

#
#pact_fp: True
switch_alpha: True

#
weight_quant_scheme: centered
act_quant_scheme: original

# =========================== Override Settings ===========================
#fp_pretrained_file: /path/to/best_model.pt
log_dir: ./results/cifar10/resnet20
adaptive_training: True
model: models.q_resnet_cifar
depth: 20
bits_list: [8,6,4,4]
bits: [8,6,4]
bits_index: [0,1,2,2]
weight_only: False
